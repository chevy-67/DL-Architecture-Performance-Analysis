{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chevy-67/DL-Architecture-Performance-Analysis/blob/main/Case_Study_CV_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIP9aoJdV5UH",
        "outputId": "86daf292-4379-4866-b62f-c08c47f9c056"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/maxsee/v6-6500?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10.5G/10.5G [02:00<00:00, 93.5MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/maxsee/v6-6500/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"maxsee/v6-6500\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqCCgBJdy7Ef"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Flatten,Conv2D,MaxPool2D,Dropout,BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import image_dataset_from_directory\n",
        "import os\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvpN-jYhvpEW"
      },
      "source": [
        "**DATASET PREPROCESSING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIfaQXCmy45c",
        "outputId": "d102f739-a87e-453d-9bda-7db6c18fcb89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Completed 45/3275"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:3452: DecompressionBombWarning: Image size (108000000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Completed 400/3275\n",
            "Failed to process 113uncy.jpg: cannot write mode RGBA as JPEG\n",
            "Completed 1106/3275\n",
            "Failed to process 115sokv.jpg: cannot write mode RGBA as JPEG\n",
            "Completed 1342/3275\n",
            "Failed to process 5zs9c8.jpg: cannot identify image file '/root/.cache/kagglehub/datasets/maxsee/v6-6500/versions/1/V5Minor100/Natural/5zs9c8.jpg'\n",
            "Completed 2665/3275"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:3452: DecompressionBombWarning: Image size (123221280 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Completed 3213/3275\n",
            "Failed to process 112xvt4.jpg: cannot identify image file '/root/.cache/kagglehub/datasets/maxsee/v6-6500/versions/1/V5Minor100/Natural/112xvt4.jpg'\n",
            "Completed 3271/3275\n",
            "Failed to process 115pufn.jpg: cannot write mode RGBA as JPEG\n",
            "Completed 3275/3275\n",
            "Done!\n",
            "Completed 324/3268\n",
            "Failed to process zb9gtk.jpg: cannot write mode RGBA as JPEG\n",
            "Completed 402/3268\n",
            "Failed to process yv22zs.jpg: cannot write mode RGBA as JPEG\n",
            "Completed 1861/3268\n",
            "Failed to process 10henz5.jpg: cannot write mode RGBA as JPEG\n",
            "Completed 3268/3268\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "input_dir1 = '/root/.cache/kagglehub/datasets/maxsee/v6-6500/versions/1/V5Minor100/Natural'\n",
        "output_dir1 = '/root/.cache/kagglehub/datasets/maxsee/v6-6500/versions/1/V5Minor100/Natural_P'\n",
        "input_dir2 = '/root/.cache/kagglehub/datasets/maxsee/v6-6500/versions/1/V5Minor100/Synthetic'\n",
        "output_dir2 = '/root/.cache/kagglehub/datasets/maxsee/v6-6500/versions/1/V5Minor100/Synthetic_P'\n",
        "target_size = (224, 224)\n",
        "\n",
        "def resize(inp_dir, out_dir):\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    image_files = [f for f in os.listdir(inp_dir) if f.lower().endswith(('.jpg', '.png'))]\n",
        "    total = len(image_files)\n",
        "\n",
        "    for i, filename in enumerate(image_files, start=1):\n",
        "        img_path = os.path.join(inp_dir, filename)\n",
        "        output_path = os.path.join(out_dir, filename)\n",
        "\n",
        "        try:\n",
        "            with Image.open(img_path) as img:\n",
        "                resized_img = img.resize(target_size)\n",
        "                resized_img.save(output_path)\n",
        "                print(f'\\rCompleted {i}/{total}', end='', flush=True)\n",
        "        except Exception as e:\n",
        "            print(f\"\\nFailed to process {filename}: {e}\")\n",
        "\n",
        "    print(\"\\nDone!\")\n",
        "\n",
        "resize(input_dir1, output_dir1)\n",
        "resize(input_dir2, output_dir2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KPCOM2VYk7j",
        "outputId": "1b0b9524-a6d7-4f31-97a0-573a2d15e356"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removed old data\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "shutil.rmtree(input_dir1)\n",
        "shutil.rmtree(input_dir2)\n",
        "print('Removed old data')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mh4sQv4EXyhi"
      },
      "source": [
        "#**Loading the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAznOTZcbZ75"
      },
      "outputs": [],
      "source": [
        "train_path = '/root/.cache/kagglehub/datasets/maxsee/v6-6500/versions/1/V5Minor100'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAHleMXaYBxj",
        "outputId": "588f9843-c0ba-477f-a07a-61109122c9dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 6535 files belonging to 2 classes.\n",
            "Using 5228 files for training.\n",
            "Found 6535 files belonging to 2 classes.\n",
            "Using 1307 files for validation.\n"
          ]
        }
      ],
      "source": [
        "train = image_dataset_from_directory(\n",
        "    train_path,\n",
        "    labels='inferred',\n",
        "    batch_size=32,\n",
        "    image_size=(224, 224),\n",
        "    seed=42,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\"\n",
        ")\n",
        "\n",
        "validation = image_dataset_from_directory(\n",
        "    train_path,\n",
        "    labels='inferred',\n",
        "    batch_size=32,\n",
        "    image_size=(224, 224),\n",
        "    seed=42,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODmX2yDwJDQf"
      },
      "source": [
        "##AlexNet Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpHGTHysu11T",
        "outputId": "e71b7ce2-e903-497a-e52e-0c3e5f2b52ea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "alexnet = Sequential([\n",
        "    Conv2D(96, kernel_size=(11, 11), strides=5, activation='relu', input_shape=(224,224,3)),\n",
        "    MaxPool2D(pool_size=(3, 3), strides=2),\n",
        "\n",
        "    Conv2D(256, kernel_size=(11, 11), strides=1,padding='same',activation='relu'),\n",
        "    MaxPool2D(pool_size=(3, 3), strides=2),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv2D(384, kernel_size=(3, 3), strides=1,padding='same' ,activation='relu'),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv2D(384, kernel_size=(3, 3), strides=1,padding='same' ,activation='relu'),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv2D(256, kernel_size=(3, 3), strides=1,padding='same' ,activation='relu'),\n",
        "    MaxPool2D(pool_size=(3, 3), strides=2),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Flatten(),\n",
        "    Dropout(0.3),\n",
        "    Dense(4096, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.2),\n",
        "    Dense(4096, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8y7XN1X1kY8"
      },
      "outputs": [],
      "source": [
        "alexnet.compile(loss='binary_crossentropy',optimizer=Adam(learning_rate=0.001),metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itovT4-XqEG0",
        "outputId": "dd85d3bb-faa3-42c9-a2fc-535bb11b226c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m 10/164\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13:03\u001b[0m 5s/step - accuracy: 0.5526 - loss: 5.1676"
          ]
        }
      ],
      "source": [
        "alexnet.fit(train,epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6sMfwVZd1E9"
      },
      "source": [
        "##EfficientNet Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zPBzcy9_si5"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input,GlobalAvgPool2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02hzK-q4xud2",
        "outputId": "7e5c2176-2969-4066-d8b1-d142ef7cf186"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "input_shape = (224,224,3)\n",
        "effnet_base_model = EfficientNetB0(weights='imagenet',include_top=False,input_shape=input_shape)\n",
        "effnet_base_model.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQDJeJu2yPV_"
      },
      "outputs": [],
      "source": [
        "inputs = Input(shape=input_shape)\n",
        "x = effnet_base_model(inputs, training=False)\n",
        "x = GlobalAvgPool2D()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "efficient_model = Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_73S39pn0Wu_"
      },
      "outputs": [],
      "source": [
        "efficient_model.compile(loss='binary_crossentropy',optimizer=Adam(learning_rate=0.001),metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qttjl04l2AHY"
      },
      "source": [
        "##Xception Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qyhTWhe1_A0"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import Xception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0iJJftecb6xq"
      },
      "outputs": [],
      "source": [
        "xception_base_model = Xception(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "xception_base_model.trainable = False\n",
        "\n",
        "inputs = Input(shape=input_shape)\n",
        "x = xception_base_model(inputs, training=False)\n",
        "x = GlobalAvgPool2D()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "xception_model = Model(inputs, outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yMgPpH6ckK4"
      },
      "outputs": [],
      "source": [
        "xception_base_model.compile(loss='binary_crossentropy',optimizer=Adam(learning_rate=0.001),metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNU8c8T8dTRF"
      },
      "source": [
        "##MobileNet Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bv_FugLZfERc"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import MobileNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xg9lBf27dSBQ"
      },
      "outputs": [],
      "source": [
        "mobilenet_base_model = Xception(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "mobilenet_base_model.trainable = False\n",
        "\n",
        "inputs = Input(shape=input_shape)\n",
        "x = mobilenet_base_model(inputs, training=False)\n",
        "x = GlobalAvgPool2D()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "mobilenet_base_model = Model(inputs, outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQ-gRtNJfb3o"
      },
      "outputs": [],
      "source": [
        "mobilenet_base_model.compile(loss='binary_crossentropy',optimizer=Adam(learning_rate=0.001),metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwXade6WfhmQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPT+EkUB3I/CUrErvT3iBKo",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}